{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yb4wtCcvu-dh",
        "outputId": "d687bc0e-ecbc-48dc-a290-23634fa2fda2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'low_bit_llama'...\n",
            "remote: Enumerating objects: 593, done.\u001b[K\n",
            "remote: Counting objects: 100% (485/485), done.\u001b[K\n",
            "remote: Compressing objects: 100% (358/358), done.\u001b[K\n",
            "remote: Total 593 (delta 198), reused 390 (delta 124), pack-reused 108 (from 1)\u001b[K\n",
            "Receiving objects: 100% (593/593), 472.68 KiB | 1.88 MiB/s, done.\n",
            "Resolving deltas: 100% (248/248), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/GreenBitAI/low_bit_llama.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd low_bit_llama\n",
        "\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-E3mpk_wXpT",
        "outputId": "8fc3041b-e7af-4b5c-e0ad-7884361c707c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/low_bit_llama\n",
            "Collecting git+https://github.com/huggingface/transformers (from -r requirements.txt (line 6))\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-fyxujg4e\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-fyxujg4e\n",
            "  Resolved https://github.com/huggingface/transformers to commit ea219ed164bead55a5513e8cfaa17a25d5613b9e\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting git+https://github.com/huggingface/peft.git@70af02a2bca5a63921790036b2c9430edf4037e2 (from -r requirements.txt (line 7))\n",
            "  Cloning https://github.com/huggingface/peft.git (to revision 70af02a2bca5a63921790036b2c9430edf4037e2) to /tmp/pip-req-build-1wndtdqw\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-req-build-1wndtdqw\n",
            "  Running command git rev-parse -q --verify 'sha^70af02a2bca5a63921790036b2c9430edf4037e2'\n",
            "  Running command git fetch -q https://github.com/huggingface/peft.git 70af02a2bca5a63921790036b2c9430edf4037e2\n",
            "  Running command git checkout -q 70af02a2bca5a63921790036b2c9430edf4037e2\n",
            "  Resolved https://github.com/huggingface/peft.git to commit 70af02a2bca5a63921790036b2c9430edf4037e2\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (1.3.0)\n",
            "Collecting colorama (from -r requirements.txt (line 2))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting datasets (from -r requirements.txt (line 3))\n",
            "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (0.2.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (2.5.1+cu124)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate->-r requirements.txt (line 1)) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate->-r requirements.txt (line 1)) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate->-r requirements.txt (line 1)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate->-r requirements.txt (line 1)) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate->-r requirements.txt (line 1)) (0.28.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate->-r requirements.txt (line 1)) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 3)) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 3)) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->-r requirements.txt (line 3))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 3)) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 3)) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 3)) (4.67.1)\n",
            "Collecting xxhash (from datasets->-r requirements.txt (line 3))\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets->-r requirements.txt (line 3))\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets->-r requirements.txt (line 3)) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 3)) (3.11.13)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->-r requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0->-r requirements.txt (line 6)) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0->-r requirements.txt (line 6)) (0.21.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (2.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 3)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 3)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 3)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 3)) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->-r requirements.txt (line 5)) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->-r requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->-r requirements.txt (line 3)) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->-r requirements.txt (line 3)) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->-r requirements.txt (line 3)) (1.17.0)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading datasets-3.3.2-py3-none-any.whl (485 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: transformers, peft\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.50.0.dev0-py3-none-any.whl size=10937326 sha256=ef4e393c84091a9d05e818e316254463d63bd78e15e77bf2dcaacf98d4f29d71\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-2z6a1f76/wheels/04/a3/f1/b88775f8e1665827525b19ac7590250f1038d947067beba9fb\n",
            "  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for peft: filename=peft-0.3.0.dev0-py3-none-any.whl size=50434 sha256=0f90f1d7125e731e47d6e7a37a57ae3e78b992d4ab100cfc4529b13ab51c443a\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/f8/88/d6b4d21588d8de0a84ab14903a4bbe0f7fe02f0f74f0a3c3ea\n",
            "Successfully built transformers peft\n",
            "Installing collected packages: xxhash, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, dill, colorama, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, transformers, datasets, peft\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.48.3\n",
            "    Uninstalling transformers-4.48.3:\n",
            "      Successfully uninstalled transformers-4.48.3\n",
            "  Attempting uninstall: peft\n",
            "    Found existing installation: peft 0.14.0\n",
            "    Uninstalling peft-0.14.0:\n",
            "      Successfully uninstalled peft-0.14.0\n",
            "Successfully installed colorama-0.4.6 datasets-3.3.2 dill-0.3.8 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 peft-0.3.0.dev0 transformers-4.50.0.dev0 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash scripts/inference/codellama_34b_w2a16g8.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_wmTExDw08K",
        "outputId": "b89e5a4d-4c9f-4c99-c1cf-fe6bacf0328b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-03-12 23:50:54.358267: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1741823454.598981    1490 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1741823454.663283    1490 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-12 23:50:55.165139: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[1m\u001b[36mLoading Model ...\u001b[0m\n",
            "config.json: 100% 588/588 [00:00<00:00, 3.07MB/s]\u001b[0m\n",
            "\u001b[0m`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n",
            "pytorch_model.bin: 100% 14.6G/14.6G [04:25<00:00, 54.9MB/s]\u001b[0m\n",
            "\u001b[0m/usr/local/lib/python3.11/dist-packages/accelerate/utils/modeling.py:1536: UserWarning: Current model requires 1690303360 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n",
            "  warnings.warn(\n",
            "\u001b[0m/usr/local/lib/python3.11/dist-packages/accelerate/utils/modeling.py:1674: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=torch.device(\"cpu\"))\n",
            "scripts/inference/codellama_34b_w2a16g8.sh: line 3:  1490 Killed                  CUDA_VISIBLE_DEVICES=0 python codellama_2b_inference.py -s 34B -v 2 -g 8\n"
          ]
        }
      ]
    },
    {
      "source": [
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install tensorflow==2.13.0"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MyJRtnOjys1h",
        "outputId": "47cf8d5e-35ec-477a-fdd1-4741af4cafb9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Collecting tensorflow==2.13.0\n",
            "  Downloading tensorflow-2.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0) (25.2.10)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.13.0)\n",
            "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0) (1.70.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0) (3.12.1)\n",
            "Collecting keras<2.14,>=2.13.1 (from tensorflow==2.13.0)\n",
            "  Downloading keras-2.13.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0) (18.1.1)\n",
            "Collecting numpy<=1.24.3,>=1.22 (from tensorflow==2.13.0)\n",
            "  Downloading numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0) (4.25.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0) (1.17.0)\n",
            "Collecting tensorboard<2.14,>=2.13 (from tensorflow==2.13.0)\n",
            "  Downloading tensorboard-2.13.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow==2.13.0)\n",
            "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0) (2.5.0)\n",
            "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow==2.13.0)\n",
            "  Downloading typing_extensions-4.5.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0) (1.17.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.13.0) (0.45.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.38.0)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.14,>=2.13->tensorflow==2.13.0)\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.2.2)\n",
            "Downloading tensorflow-2.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (524.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.2/524.2 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m102.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m107.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Installing collected packages: typing-extensions, tensorflow-estimator, numpy, keras, gast, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.12.2\n",
            "    Uninstalling typing_extensions-4.12.2:\n",
            "      Successfully uninstalled typing_extensions-4.12.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.8.0\n",
            "    Uninstalling keras-3.8.0:\n",
            "      Successfully uninstalled keras-3.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.6.0\n",
            "    Uninstalling gast-0.6.0:\n",
            "      Successfully uninstalled gast-0.6.0\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.1\n",
            "    Uninstalling google-auth-oauthlib-1.2.1:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.18.0\n",
            "    Uninstalling tensorboard-2.18.0:\n",
            "      Successfully uninstalled tensorboard-2.18.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.18.0\n",
            "    Uninstalling tensorflow-2.18.0:\n",
            "      Successfully uninstalled tensorflow-2.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.13.0 which is incompatible.\n",
            "langchain-core 0.3.43 requires typing-extensions>=4.7, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "sqlalchemy 2.0.38 requires typing-extensions>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.24.3 which is incompatible.\n",
            "pydantic-core 2.27.2 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "openai 1.61.1 requires typing-extensions<5,>=4.11, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\n",
            "nibabel 5.3.2 requires typing-extensions>=4.6; python_version < \"3.13\", but you have typing-extensions 4.5.0 which is incompatible.\n",
            "pydantic 2.10.6 requires typing-extensions>=4.12.2, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "typeguard 4.4.2 requires typing_extensions>=4.10.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "blosc2 3.2.0 requires numpy>=1.26, but you have numpy 1.24.3 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\n",
            "google-genai 1.4.0 requires typing-extensions<5.0.0dev,>=4.11.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "albucore 0.0.23 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n",
            "altair 5.5.0 requires typing-extensions>=4.10.0; python_version < \"3.14\", but you have typing-extensions 4.5.0 which is incompatible.\n",
            "albumentations 2.0.5 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.13.0 which is incompatible.\n",
            "torch 2.5.1+cu124 requires typing-extensions>=4.8.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "pymc 5.20.1 requires numpy>=1.25.0, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gast-0.4.0 google-auth-oauthlib-1.0.0 keras-2.13.1 numpy-1.24.3 tensorboard-2.13.0 tensorflow-2.13.0 tensorflow-estimator-2.13.0 typing-extensions-4.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google_auth_oauthlib",
                  "numpy"
                ]
              },
              "id": "7641f4bde4284b15ac653607ffff65a0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "source": [
        "!pip install --upgrade --force-reinstall tensorflow\n",
        "!pip install --upgrade --force-reinstall torch torchvision torchaudio"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "M3VefacWywuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!bash scripts/inference/codellama_34b_w2a16g8.sh -h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hz6rAUnYy41Z",
        "outputId": "04da3fe2-2ed9-4d24-e8f9-7ecc95fb1a24"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bash: scripts/inference/codellama_34b_w2a16g8.sh: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "source": [
        "!pip install --upgrade --force-reinstall transformers"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nCF2XGu0zp3h",
        "outputId": "b36421dd-f690-4f6a-b008-20731ed3b75e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting filelock (from transformers)\n",
            "  Downloading filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting huggingface-hub<1.0,>=0.26.0 (from transformers)\n",
            "  Downloading huggingface_hub-0.29.3-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting numpy>=1.17 (from transformers)\n",
            "  Downloading numpy-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging>=20.0 (from transformers)\n",
            "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting pyyaml>=5.1 (from transformers)\n",
            "  Downloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting regex!=2019.12.17 (from transformers)\n",
            "  Downloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests (from transformers)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
            "  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting safetensors>=0.4.1 (from transformers)\n",
            "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting tqdm>=4.27 (from transformers)\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.26.0->transformers)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub<1.0,>=0.26.0->transformers)\n",
            "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests->transformers)\n",
            "  Downloading charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
            "Collecting idna<4,>=2.5 (from requests->transformers)\n",
            "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->transformers)\n",
            "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests->transformers)\n",
            "  Downloading certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
            "Downloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m97.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.29.3-py3-none-any.whl (468 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (762 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m763.0/763.0 kB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m792.7/792.7 kB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m91.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filelock-3.17.0-py3-none-any.whl (16 kB)\n",
            "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.9/143.9 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: urllib3, typing-extensions, tqdm, safetensors, regex, pyyaml, packaging, numpy, idna, fsspec, filelock, charset-normalizer, certifi, requests, huggingface-hub, tokenizers, transformers\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.3.0\n",
            "    Uninstalling urllib3-2.3.0:\n",
            "      Successfully uninstalled urllib3-2.3.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: safetensors\n",
            "    Found existing installation: safetensors 0.5.3\n",
            "    Uninstalling safetensors-0.5.3:\n",
            "      Successfully uninstalled safetensors-0.5.3\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2024.11.6\n",
            "    Uninstalling regex-2024.11.6:\n",
            "      Successfully uninstalled regex-2024.11.6\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0.2\n",
            "    Uninstalling PyYAML-6.0.2:\n",
            "      Successfully uninstalled PyYAML-6.0.2\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.2\n",
            "    Uninstalling packaging-24.2:\n",
            "      Successfully uninstalled packaging-24.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.24.3\n",
            "    Uninstalling numpy-1.24.3:\n",
            "      Successfully uninstalled numpy-1.24.3\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.17.0\n",
            "    Uninstalling filelock-3.17.0:\n",
            "      Successfully uninstalled filelock-3.17.0\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.1\n",
            "    Uninstalling charset-normalizer-3.4.1:\n",
            "      Successfully uninstalled charset-normalizer-3.4.1\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2025.1.31\n",
            "    Uninstalling certifi-2025.1.31:\n",
            "      Successfully uninstalled certifi-2025.1.31\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.28.1\n",
            "    Uninstalling huggingface-hub-0.28.1:\n",
            "      Successfully uninstalled huggingface-hub-0.28.1\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.0\n",
            "    Uninstalling tokenizers-0.21.0:\n",
            "      Successfully uninstalled tokenizers-0.21.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.50.0.dev0\n",
            "    Uninstalling transformers-4.50.0.dev0:\n",
            "      Successfully uninstalled transformers-4.50.0.dev0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.13.0 requires numpy<=1.24.3,>=1.22, but you have numpy 2.2.3 which is incompatible.\n",
            "tensorflow 2.13.0 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.12.2 which is incompatible.\n",
            "datasets 3.3.2 requires fsspec[http]<=2024.12.0,>=2023.1.0, but you have fsspec 2025.3.0 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.13.0 which is incompatible.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2025.3.0 which is incompatible.\n",
            "pytensor 2.27.1 requires numpy<2,>=1.17.0, but you have numpy 2.2.3 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.13.0 which is incompatible.\n",
            "thinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.2.3 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed certifi-2025.1.31 charset-normalizer-3.4.1 filelock-3.17.0 fsspec-2025.3.0 huggingface-hub-0.29.3 idna-3.10 numpy-2.2.3 packaging-24.2 pyyaml-6.0.2 regex-2024.11.6 requests-2.32.3 safetensors-0.5.3 tokenizers-0.21.0 tqdm-4.67.1 transformers-4.49.0 typing-extensions-4.12.2 urllib3-2.3.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi",
                  "charset_normalizer",
                  "requests",
                  "tqdm"
                ]
              },
              "id": "3feb65d94da84731a4525c437a3f0fc1"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "source": [
        "!pip install \"numpy<2\""
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnLgO2_Ozibh",
        "outputId": "84cff50d-09f4-48a0-956d-935fa523450f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.11/dist-packages (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zKh34s50y6cB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "%cd /content/low_bit_llama\n",
        "!bash scripts/inference/codellama_34b_w2a16g8.sh --offload_buffers=True"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ro3uyI4y0oQ",
        "outputId": "1897585e-9ace-421a-a87e-2c2ca601d965"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/low_bit_llama\n",
            "2025-03-13 00:02:21.360540: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-03-13 00:02:21.411257: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.2.3 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"/content/low_bit_llama/codellama_2b_inference.py\", line 32, in <module>\n",
            "    model, tokenizer = load_llama_model(model_uri, cache_dir=cache_dir, groupsize=args.groupsize, double_groupsize=double_groupsize, bits=2, half=True, v1=v1, asym=asym)\n",
            "  File \"/content/low_bit_llama/model.py\", line 136, in load_llama_model\n",
            "    from transformers import LlamaConfig, LlamaForCausalLM, LlamaTokenizer\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1852, in __getattr__\n",
            "    value = getattr(module, name)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1851, in __getattr__\n",
            "    module = self._get_module(self._class_to_module[name])\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1863, in _get_module\n",
            "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
            "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\", line 39, in <module>\n",
            "    from ...modeling_utils import ALL_ATTENTION_FUNCTIONS, PreTrainedModel\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 53, in <module>\n",
            "    from .loss.loss_utils import LOSS_MAPPING\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/loss/loss_utils.py\", line 19, in <module>\n",
            "    from .loss_deformable_detr import DeformableDetrForObjectDetectionLoss, DeformableDetrForSegmentationLoss\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/loss/loss_deformable_detr.py\", line 4, in <module>\n",
            "    from ..image_transforms import center_to_corners_format\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/image_transforms.py\", line 48, in <module>\n",
            "    import tensorflow as tf\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/__init__.py\", line 38, in <module>\n",
            "    from tensorflow.python.tools import module_util as _module_util\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/__init__.py\", line 37, in <module>\n",
            "    from tensorflow.python.eager import context\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\", line 34, in <module>\n",
            "    from tensorflow.python.client import pywrap_tf_session\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/client/pywrap_tf_session.py\", line 19, in <module>\n",
            "    from tensorflow.python.client._pywrap_tf_session import *\n",
            "\u001b[0m\u001b[0mAttributeError\u001b[0m: \u001b[0m_ARRAY_API not found\u001b[0m\n",
            "\u001b[0m\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.2.3 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"/content/low_bit_llama/codellama_2b_inference.py\", line 32, in <module>\n",
            "    model, tokenizer = load_llama_model(model_uri, cache_dir=cache_dir, groupsize=args.groupsize, double_groupsize=double_groupsize, bits=2, half=True, v1=v1, asym=asym)\n",
            "  File \"/content/low_bit_llama/model.py\", line 136, in load_llama_model\n",
            "    from transformers import LlamaConfig, LlamaForCausalLM, LlamaTokenizer\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1852, in __getattr__\n",
            "    value = getattr(module, name)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1851, in __getattr__\n",
            "    module = self._get_module(self._class_to_module[name])\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1863, in _get_module\n",
            "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
            "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\", line 39, in <module>\n",
            "    from ...modeling_utils import ALL_ATTENTION_FUNCTIONS, PreTrainedModel\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 53, in <module>\n",
            "    from .loss.loss_utils import LOSS_MAPPING\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/loss/loss_utils.py\", line 19, in <module>\n",
            "    from .loss_deformable_detr import DeformableDetrForObjectDetectionLoss, DeformableDetrForSegmentationLoss\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/loss/loss_deformable_detr.py\", line 4, in <module>\n",
            "    from ..image_transforms import center_to_corners_format\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/image_transforms.py\", line 48, in <module>\n",
            "    import tensorflow as tf\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/__init__.py\", line 38, in <module>\n",
            "    from tensorflow.python.tools import module_util as _module_util\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/__init__.py\", line 37, in <module>\n",
            "    from tensorflow.python.eager import context\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\", line 36, in <module>\n",
            "    from tensorflow.python.eager import execute\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\", line 21, in <module>\n",
            "    from tensorflow.python.framework import dtypes\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/dtypes.py\", line 30, in <module>\n",
            "    from tensorflow.python.lib.core import _pywrap_float8\n",
            "\u001b[0m\u001b[0mAttributeError\u001b[0m: \u001b[0m_ARRAY_API not found\u001b[0m\n",
            "\u001b[0m\u001b[0mImportError\u001b[0m: \u001b[0mnumpy.core._multiarray_umath failed to import\u001b[0m\n",
            "\u001b[0m\u001b[0mImportError\u001b[0m: \u001b[0mnumpy.core.umath failed to import\u001b[0m\n",
            "\u001b[0m\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.2.3 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"/content/low_bit_llama/codellama_2b_inference.py\", line 32, in <module>\n",
            "    model, tokenizer = load_llama_model(model_uri, cache_dir=cache_dir, groupsize=args.groupsize, double_groupsize=double_groupsize, bits=2, half=True, v1=v1, asym=asym)\n",
            "  File \"/content/low_bit_llama/model.py\", line 136, in load_llama_model\n",
            "    from transformers import LlamaConfig, LlamaForCausalLM, LlamaTokenizer\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1852, in __getattr__\n",
            "    value = getattr(module, name)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1851, in __getattr__\n",
            "    module = self._get_module(self._class_to_module[name])\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1863, in _get_module\n",
            "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
            "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\", line 39, in <module>\n",
            "    from ...modeling_utils import ALL_ATTENTION_FUNCTIONS, PreTrainedModel\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 53, in <module>\n",
            "    from .loss.loss_utils import LOSS_MAPPING\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/loss/loss_utils.py\", line 19, in <module>\n",
            "    from .loss_deformable_detr import DeformableDetrForObjectDetectionLoss, DeformableDetrForSegmentationLoss\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/loss/loss_deformable_detr.py\", line 4, in <module>\n",
            "    from ..image_transforms import center_to_corners_format\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/image_transforms.py\", line 48, in <module>\n",
            "    import tensorflow as tf\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/__init__.py\", line 38, in <module>\n",
            "    from tensorflow.python.tools import module_util as _module_util\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/__init__.py\", line 37, in <module>\n",
            "    from tensorflow.python.eager import context\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\", line 36, in <module>\n",
            "    from tensorflow.python.eager import execute\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\", line 21, in <module>\n",
            "    from tensorflow.python.framework import dtypes\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/dtypes.py\", line 30, in <module>\n",
            "    from tensorflow.python.lib.core import _pywrap_float8\n",
            "\u001b[0m\u001b[0mAttributeError\u001b[0m: \u001b[0m_ARRAY_API not found\u001b[0m\n",
            "\u001b[0m\u001b[0mImportError\u001b[0m: \u001b[0mnumpy.core._multiarray_umath failed to import\u001b[0m\n",
            "\u001b[0m\u001b[0mImportError\u001b[0m: \u001b[0mnumpy.core.umath failed to import\u001b[0m\n",
            "\u001b[0m\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.2.3 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"/content/low_bit_llama/codellama_2b_inference.py\", line 32, in <module>\n",
            "    model, tokenizer = load_llama_model(model_uri, cache_dir=cache_dir, groupsize=args.groupsize, double_groupsize=double_groupsize, bits=2, half=True, v1=v1, asym=asym)\n",
            "  File \"/content/low_bit_llama/model.py\", line 136, in load_llama_model\n",
            "    from transformers import LlamaConfig, LlamaForCausalLM, LlamaTokenizer\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1852, in __getattr__\n",
            "    value = getattr(module, name)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1851, in __getattr__\n",
            "    module = self._get_module(self._class_to_module[name])\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1863, in _get_module\n",
            "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
            "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\", line 39, in <module>\n",
            "    from ...modeling_utils import ALL_ATTENTION_FUNCTIONS, PreTrainedModel\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 53, in <module>\n",
            "    from .loss.loss_utils import LOSS_MAPPING\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/loss/loss_utils.py\", line 19, in <module>\n",
            "    from .loss_deformable_detr import DeformableDetrForObjectDetectionLoss, DeformableDetrForSegmentationLoss\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/loss/loss_deformable_detr.py\", line 4, in <module>\n",
            "    from ..image_transforms import center_to_corners_format\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/image_transforms.py\", line 48, in <module>\n",
            "    import tensorflow as tf\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/__init__.py\", line 38, in <module>\n",
            "    from tensorflow.python.tools import module_util as _module_util\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/__init__.py\", line 37, in <module>\n",
            "    from tensorflow.python.eager import context\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\", line 36, in <module>\n",
            "    from tensorflow.python.eager import execute\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\", line 21, in <module>\n",
            "    from tensorflow.python.framework import dtypes\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/dtypes.py\", line 35, in <module>\n",
            "    from tensorflow.tsl.python.lib.core import pywrap_bfloat16\n",
            "\u001b[0m\u001b[0mAttributeError\u001b[0m: \u001b[0m_ARRAY_API not found\u001b[0m\n",
            "\u001b[0m\u001b[0mImportError\u001b[0m: \u001b[0mnumpy.core._multiarray_umath failed to import\u001b[0m\n",
            "\u001b[0m\u001b[0mImportError\u001b[0m: \u001b[0mnumpy.core.umath failed to import\u001b[0m\n",
            "\u001b[0m\u001b[0mTraceback (most recent call last):\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1863, in _get_module\n",
            "\u001b[0m\u001b[0m    \u001b[0mreturn importlib.import_module(\".\" + module_name, self.__name__)\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
            "\u001b[0m\u001b[0m    \u001b[0mreturn _bootstrap._gcd_import(name[level:], package, level)\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\n",
            "\u001b[0m\u001b[0m  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n",
            "\u001b[0m\u001b[0m  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\n",
            "\u001b[0m\u001b[0m  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\n",
            "\u001b[0m\u001b[0m  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
            "\u001b[0m\u001b[0m  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\", line 39, in <module>\n",
            "\u001b[0m\u001b[0m    \u001b[0mfrom ...modeling_utils import ALL_ATTENTION_FUNCTIONS, PreTrainedModel\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 53, in <module>\n",
            "\u001b[0m\u001b[0m    \u001b[0mfrom .loss.loss_utils import LOSS_MAPPING\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/transformers/loss/loss_utils.py\", line 19, in <module>\n",
            "\u001b[0m\u001b[0m    \u001b[0mfrom .loss_deformable_detr import DeformableDetrForObjectDetectionLoss, DeformableDetrForSegmentationLoss\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/transformers/loss/loss_deformable_detr.py\", line 4, in <module>\n",
            "\u001b[0m\u001b[0m    \u001b[0mfrom ..image_transforms import center_to_corners_format\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/transformers/image_transforms.py\", line 48, in <module>\n",
            "\u001b[0m\u001b[0m    \u001b[0mimport tensorflow as tf\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/__init__.py\", line 38, in <module>\n",
            "\u001b[0m\u001b[0m    \u001b[0mfrom tensorflow.python.tools import module_util as _module_util\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/__init__.py\", line 37, in <module>\n",
            "\u001b[0m\u001b[0m    \u001b[0mfrom tensorflow.python.eager import context\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\", line 36, in <module>\n",
            "\u001b[0m\u001b[0m    \u001b[0mfrom tensorflow.python.eager import execute\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\", line 21, in <module>\n",
            "\u001b[0m\u001b[0m    \u001b[0mfrom tensorflow.python.framework import dtypes\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/dtypes.py\", line 38, in <module>\n",
            "\u001b[0m\u001b[0m    \u001b[0m_np_bfloat16 = pywrap_bfloat16.bfloat16_type()\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0mTypeError\u001b[0m: \u001b[0mUnable to convert function return value to a Python type! The signature was\n",
            "\t() -> handle\u001b[0m\n",
            "\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0mThe above exception was the direct cause of the following exception:\n",
            "\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0mTraceback (most recent call last):\n",
            "\u001b[0m\u001b[0m  File \"/content/low_bit_llama/codellama_2b_inference.py\", line 32, in <module>\n",
            "\u001b[0m\u001b[0m    \u001b[0mmodel, tokenizer = load_llama_model(model_uri, cache_dir=cache_dir, groupsize=args.groupsize, double_groupsize=double_groupsize, bits=2, half=True, v1=v1, asym=asym)\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/content/low_bit_llama/model.py\", line 136, in load_llama_model\n",
            "\u001b[0m\u001b[0m    \u001b[0mfrom transformers import LlamaConfig, LlamaForCausalLM, LlamaTokenizer\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"<frozen importlib._bootstrap>\", line 1229, in _handle_fromlist\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1852, in __getattr__\n",
            "\u001b[0m\u001b[0m    \u001b[0mvalue = getattr(module, name)\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1851, in __getattr__\n",
            "\u001b[0m\u001b[0m    \u001b[0mmodule = self._get_module(self._class_to_module[name])\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1865, in _get_module\n",
            "\u001b[0m\u001b[0m    \u001b[0mraise RuntimeError(\u001b[0m\n",
            "\u001b[0m\u001b[0mRuntimeError\u001b[0m: \u001b[0mFailed to import transformers.models.llama.modeling_llama because of the following error (look up to see its traceback):\n",
            "Unable to convert function return value to a Python type! The signature was\n",
            "\t() -> handle\u001b[0m\n",
            "\u001b[0m\u001b[0m"
          ]
        }
      ]
    },
    {
      "source": [
        "!pip install --upgrade --force-reinstall transformers"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "qWWCKU850BL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/low_bit_llama\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Lx6Q08u0Gt5",
        "outputId": "912c9133-2f54-4cee-80ff-ecd2b7b504dd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/low_bit_llama\n",
            "Collecting git+https://github.com/huggingface/transformers (from -r requirements.txt (line 6))\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-71guc7ra\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-71guc7ra\n",
            "  Resolved https://github.com/huggingface/transformers to commit ea219ed164bead55a5513e8cfaa17a25d5613b9e\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting git+https://github.com/huggingface/peft.git@70af02a2bca5a63921790036b2c9430edf4037e2 (from -r requirements.txt (line 7))\n",
            "  Cloning https://github.com/huggingface/peft.git (to revision 70af02a2bca5a63921790036b2c9430edf4037e2) to /tmp/pip-req-build-erwir_ns\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-req-build-erwir_ns\n",
            "  Running command git rev-parse -q --verify 'sha^70af02a2bca5a63921790036b2c9430edf4037e2'\n",
            "  Running command git fetch -q https://github.com/huggingface/peft.git 70af02a2bca5a63921790036b2c9430edf4037e2\n",
            "  Running command git checkout -q 70af02a2bca5a63921790036b2c9430edf4037e2\n",
            "  Resolved https://github.com/huggingface/peft.git to commit 70af02a2bca5a63921790036b2c9430edf4037e2\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (0.4.6)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (3.3.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (0.2.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (2.5.1+cu124)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate->-r requirements.txt (line 1)) (2.2.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate->-r requirements.txt (line 1)) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate->-r requirements.txt (line 1)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate->-r requirements.txt (line 1)) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate->-r requirements.txt (line 1)) (0.29.3)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate->-r requirements.txt (line 1)) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 3)) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 3)) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 3)) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 3)) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 3)) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 3)) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 3)) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 3)) (0.70.16)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets->-r requirements.txt (line 3))\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 3)) (3.11.13)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->-r requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0->-r requirements.txt (line 6)) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0->-r requirements.txt (line 6)) (0.21.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (2.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 3)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 3)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 3)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 3)) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->-r requirements.txt (line 5)) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->-r requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->-r requirements.txt (line 3)) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->-r requirements.txt (line 3)) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->-r requirements.txt (line 3)) (1.17.0)\n",
            "Downloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: transformers\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.50.0.dev0-py3-none-any.whl size=10937326 sha256=5405eb7bfecd45f940b4146476136c19324d1177c8b5f10b1a73b2b1edd6b3d1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-gayd6mes/wheels/04/a3/f1/b88775f8e1665827525b19ac7590250f1038d947067beba9fb\n",
            "Successfully built transformers\n",
            "Installing collected packages: fsspec, transformers\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.49.0\n",
            "    Uninstalling transformers-4.49.0:\n",
            "      Successfully uninstalled transformers-4.49.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed fsspec-2024.12.0 transformers-4.50.0.dev0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/low_bit_llama\n",
        "!bash scripts/inference/codellama_34b_w2a16g8.sh --offload_buffers=True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upTvJ3ZF0MJb",
        "outputId": "9311382f-12cb-4f68-9f75-0ce54a2e8557"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/low_bit_llama\n",
            "2025-03-13 00:06:11.252819: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-03-13 00:06:11.300694: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.2.3 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"/content/low_bit_llama/codellama_2b_inference.py\", line 32, in <module>\n",
            "    model, tokenizer = load_llama_model(model_uri, cache_dir=cache_dir, groupsize=args.groupsize, double_groupsize=double_groupsize, bits=2, half=True, v1=v1, asym=asym)\n",
            "  File \"/content/low_bit_llama/model.py\", line 136, in load_llama_model\n",
            "    from transformers import LlamaConfig, LlamaForCausalLM, LlamaTokenizer\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1938, in __getattr__\n",
            "    value = getattr(module, name)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1937, in __getattr__\n",
            "    module = self._get_module(self._class_to_module[name])\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1949, in _get_module\n",
            "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
            "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\", line 39, in <module>\n",
            "    from ...modeling_utils import ALL_ATTENTION_FUNCTIONS, PreTrainedModel\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 61, in <module>\n",
            "    from .loss.loss_utils import LOSS_MAPPING\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/loss/loss_utils.py\", line 19, in <module>\n",
            "    from .loss_deformable_detr import DeformableDetrForObjectDetectionLoss, DeformableDetrForSegmentationLoss\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/loss/loss_deformable_detr.py\", line 4, in <module>\n",
            "    from ..image_transforms import center_to_corners_format\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/image_transforms.py\", line 49, in <module>\n",
            "    import tensorflow as tf\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/__init__.py\", line 38, in <module>\n",
            "    from tensorflow.python.tools import module_util as _module_util\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/__init__.py\", line 37, in <module>\n",
            "    from tensorflow.python.eager import context\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\", line 34, in <module>\n",
            "    from tensorflow.python.client import pywrap_tf_session\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/client/pywrap_tf_session.py\", line 19, in <module>\n",
            "    from tensorflow.python.client._pywrap_tf_session import *\n",
            "\u001b[0m\u001b[0mAttributeError\u001b[0m: \u001b[0m_ARRAY_API not found\u001b[0m\n",
            "\u001b[0m\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.2.3 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"/content/low_bit_llama/codellama_2b_inference.py\", line 32, in <module>\n",
            "    model, tokenizer = load_llama_model(model_uri, cache_dir=cache_dir, groupsize=args.groupsize, double_groupsize=double_groupsize, bits=2, half=True, v1=v1, asym=asym)\n",
            "  File \"/content/low_bit_llama/model.py\", line 136, in load_llama_model\n",
            "    from transformers import LlamaConfig, LlamaForCausalLM, LlamaTokenizer\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1938, in __getattr__\n",
            "    value = getattr(module, name)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1937, in __getattr__\n",
            "    module = self._get_module(self._class_to_module[name])\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1949, in _get_module\n",
            "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
            "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\", line 39, in <module>\n",
            "    from ...modeling_utils import ALL_ATTENTION_FUNCTIONS, PreTrainedModel\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 61, in <module>\n",
            "    from .loss.loss_utils import LOSS_MAPPING\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/loss/loss_utils.py\", line 19, in <module>\n",
            "    from .loss_deformable_detr import DeformableDetrForObjectDetectionLoss, DeformableDetrForSegmentationLoss\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/loss/loss_deformable_detr.py\", line 4, in <module>\n",
            "    from ..image_transforms import center_to_corners_format\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/image_transforms.py\", line 49, in <module>\n",
            "    import tensorflow as tf\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/__init__.py\", line 38, in <module>\n",
            "    from tensorflow.python.tools import module_util as _module_util\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/__init__.py\", line 37, in <module>\n",
            "    from tensorflow.python.eager import context\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\", line 36, in <module>\n",
            "    from tensorflow.python.eager import execute\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\", line 21, in <module>\n",
            "    from tensorflow.python.framework import dtypes\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/dtypes.py\", line 30, in <module>\n",
            "    from tensorflow.python.lib.core import _pywrap_float8\n",
            "\u001b[0m\u001b[0mAttributeError\u001b[0m: \u001b[0m_ARRAY_API not found\u001b[0m\n",
            "\u001b[0m\u001b[0mImportError\u001b[0m: \u001b[0mnumpy.core._multiarray_umath failed to import\u001b[0m\n",
            "\u001b[0m\u001b[0mImportError\u001b[0m: \u001b[0mnumpy.core.umath failed to import\u001b[0m\n",
            "\u001b[0m\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.2.3 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"/content/low_bit_llama/codellama_2b_inference.py\", line 32, in <module>\n",
            "    model, tokenizer = load_llama_model(model_uri, cache_dir=cache_dir, groupsize=args.groupsize, double_groupsize=double_groupsize, bits=2, half=True, v1=v1, asym=asym)\n",
            "  File \"/content/low_bit_llama/model.py\", line 136, in load_llama_model\n",
            "    from transformers import LlamaConfig, LlamaForCausalLM, LlamaTokenizer\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1938, in __getattr__\n",
            "    value = getattr(module, name)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1937, in __getattr__\n",
            "    module = self._get_module(self._class_to_module[name])\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1949, in _get_module\n",
            "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
            "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\", line 39, in <module>\n",
            "    from ...modeling_utils import ALL_ATTENTION_FUNCTIONS, PreTrainedModel\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 61, in <module>\n",
            "    from .loss.loss_utils import LOSS_MAPPING\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/loss/loss_utils.py\", line 19, in <module>\n",
            "    from .loss_deformable_detr import DeformableDetrForObjectDetectionLoss, DeformableDetrForSegmentationLoss\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/loss/loss_deformable_detr.py\", line 4, in <module>\n",
            "    from ..image_transforms import center_to_corners_format\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/image_transforms.py\", line 49, in <module>\n",
            "    import tensorflow as tf\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/__init__.py\", line 38, in <module>\n",
            "    from tensorflow.python.tools import module_util as _module_util\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/__init__.py\", line 37, in <module>\n",
            "    from tensorflow.python.eager import context\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\", line 36, in <module>\n",
            "    from tensorflow.python.eager import execute\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\", line 21, in <module>\n",
            "    from tensorflow.python.framework import dtypes\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/dtypes.py\", line 30, in <module>\n",
            "    from tensorflow.python.lib.core import _pywrap_float8\n",
            "\u001b[0m\u001b[0mAttributeError\u001b[0m: \u001b[0m_ARRAY_API not found\u001b[0m\n",
            "\u001b[0m\u001b[0mImportError\u001b[0m: \u001b[0mnumpy.core._multiarray_umath failed to import\u001b[0m\n",
            "\u001b[0m\u001b[0mImportError\u001b[0m: \u001b[0mnumpy.core.umath failed to import\u001b[0m\n",
            "\u001b[0m\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.2.3 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"/content/low_bit_llama/codellama_2b_inference.py\", line 32, in <module>\n",
            "    model, tokenizer = load_llama_model(model_uri, cache_dir=cache_dir, groupsize=args.groupsize, double_groupsize=double_groupsize, bits=2, half=True, v1=v1, asym=asym)\n",
            "  File \"/content/low_bit_llama/model.py\", line 136, in load_llama_model\n",
            "    from transformers import LlamaConfig, LlamaForCausalLM, LlamaTokenizer\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1938, in __getattr__\n",
            "    value = getattr(module, name)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1937, in __getattr__\n",
            "    module = self._get_module(self._class_to_module[name])\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1949, in _get_module\n",
            "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
            "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\", line 39, in <module>\n",
            "    from ...modeling_utils import ALL_ATTENTION_FUNCTIONS, PreTrainedModel\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 61, in <module>\n",
            "    from .loss.loss_utils import LOSS_MAPPING\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/loss/loss_utils.py\", line 19, in <module>\n",
            "    from .loss_deformable_detr import DeformableDetrForObjectDetectionLoss, DeformableDetrForSegmentationLoss\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/loss/loss_deformable_detr.py\", line 4, in <module>\n",
            "    from ..image_transforms import center_to_corners_format\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/image_transforms.py\", line 49, in <module>\n",
            "    import tensorflow as tf\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/__init__.py\", line 38, in <module>\n",
            "    from tensorflow.python.tools import module_util as _module_util\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/__init__.py\", line 37, in <module>\n",
            "    from tensorflow.python.eager import context\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\", line 36, in <module>\n",
            "    from tensorflow.python.eager import execute\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\", line 21, in <module>\n",
            "    from tensorflow.python.framework import dtypes\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/dtypes.py\", line 35, in <module>\n",
            "    from tensorflow.tsl.python.lib.core import pywrap_bfloat16\n",
            "\u001b[0m\u001b[0mAttributeError\u001b[0m: \u001b[0m_ARRAY_API not found\u001b[0m\n",
            "\u001b[0m\u001b[0mImportError\u001b[0m: \u001b[0mnumpy.core._multiarray_umath failed to import\u001b[0m\n",
            "\u001b[0m\u001b[0mImportError\u001b[0m: \u001b[0mnumpy.core.umath failed to import\u001b[0m\n",
            "\u001b[0m\u001b[0mTraceback (most recent call last):\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1949, in _get_module\n",
            "\u001b[0m\u001b[0m    \u001b[0mreturn importlib.import_module(\".\" + module_name, self.__name__)\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
            "\u001b[0m\u001b[0m    \u001b[0mreturn _bootstrap._gcd_import(name[level:], package, level)\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\n",
            "\u001b[0m\u001b[0m  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n",
            "\u001b[0m\u001b[0m  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\n",
            "\u001b[0m\u001b[0m  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\n",
            "\u001b[0m\u001b[0m  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
            "\u001b[0m\u001b[0m  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\", line 39, in <module>\n",
            "\u001b[0m\u001b[0m    \u001b[0mfrom ...modeling_utils import ALL_ATTENTION_FUNCTIONS, PreTrainedModel\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 61, in <module>\n",
            "\u001b[0m\u001b[0m    \u001b[0mfrom .loss.loss_utils import LOSS_MAPPING\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/transformers/loss/loss_utils.py\", line 19, in <module>\n",
            "\u001b[0m\u001b[0m    \u001b[0mfrom .loss_deformable_detr import DeformableDetrForObjectDetectionLoss, DeformableDetrForSegmentationLoss\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/transformers/loss/loss_deformable_detr.py\", line 4, in <module>\n",
            "\u001b[0m\u001b[0m    \u001b[0mfrom ..image_transforms import center_to_corners_format\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/transformers/image_transforms.py\", line 49, in <module>\n",
            "\u001b[0m\u001b[0m    \u001b[0mimport tensorflow as tf\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/__init__.py\", line 38, in <module>\n",
            "\u001b[0m\u001b[0m    \u001b[0mfrom tensorflow.python.tools import module_util as _module_util\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/__init__.py\", line 37, in <module>\n",
            "\u001b[0m\u001b[0m    \u001b[0mfrom tensorflow.python.eager import context\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\", line 36, in <module>\n",
            "\u001b[0m\u001b[0m    \u001b[0mfrom tensorflow.python.eager import execute\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\", line 21, in <module>\n",
            "\u001b[0m\u001b[0m    \u001b[0mfrom tensorflow.python.framework import dtypes\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/dtypes.py\", line 38, in <module>\n",
            "\u001b[0m\u001b[0m    \u001b[0m_np_bfloat16 = pywrap_bfloat16.bfloat16_type()\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0mTypeError\u001b[0m: \u001b[0mUnable to convert function return value to a Python type! The signature was\n",
            "\t() -> handle\u001b[0m\n",
            "\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0mThe above exception was the direct cause of the following exception:\n",
            "\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0mTraceback (most recent call last):\n",
            "\u001b[0m\u001b[0m  File \"/content/low_bit_llama/codellama_2b_inference.py\", line 32, in <module>\n",
            "\u001b[0m\u001b[0m    \u001b[0mmodel, tokenizer = load_llama_model(model_uri, cache_dir=cache_dir, groupsize=args.groupsize, double_groupsize=double_groupsize, bits=2, half=True, v1=v1, asym=asym)\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/content/low_bit_llama/model.py\", line 136, in load_llama_model\n",
            "\u001b[0m\u001b[0m    \u001b[0mfrom transformers import LlamaConfig, LlamaForCausalLM, LlamaTokenizer\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"<frozen importlib._bootstrap>\", line 1229, in _handle_fromlist\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1938, in __getattr__\n",
            "\u001b[0m\u001b[0m    \u001b[0mvalue = getattr(module, name)\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1937, in __getattr__\n",
            "\u001b[0m\u001b[0m    \u001b[0mmodule = self._get_module(self._class_to_module[name])\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1951, in _get_module\n",
            "\u001b[0m\u001b[0m    \u001b[0mraise RuntimeError(\u001b[0m\n",
            "\u001b[0m\u001b[0mRuntimeError\u001b[0m: \u001b[0mFailed to import transformers.models.llama.modeling_llama because of the following error (look up to see its traceback):\n",
            "Unable to convert function return value to a Python type! The signature was\n",
            "\t() -> handle\u001b[0m\n",
            "\u001b[0m\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "/content/low_bit_llama/scripts/inference/llama2_7b_w2a16g32.sh"
      ],
      "metadata": {
        "id": "ZEWgMAED0p6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/low_bit_llama\n",
        "!bash scripts/inference/llama2_7b_w2a16g32.sh --offload_buffers=True"
      ],
      "metadata": {
        "id": "bIcUAzl11Edq",
        "outputId": "a401ddc6-cbed-4cb2-91b4-eb6bda6898eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/low_bit_llama\n",
            "2025-03-13 00:08:27.565883: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-03-13 00:08:27.614851: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.2.3 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"/content/low_bit_llama/llama_2b_inference.py\", line 62, in <module>\n",
            "    model, tokenizer = load_llama_model(model_uri, cache_dir=cache_dir, groupsize=args.groupsize, double_groupsize=double_groupsize, v1=v1, bits=2, half=True, asym=asym)\n",
            "  File \"/content/low_bit_llama/model.py\", line 136, in load_llama_model\n",
            "    from transformers import LlamaConfig, LlamaForCausalLM, LlamaTokenizer\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1938, in __getattr__\n",
            "    value = getattr(module, name)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1937, in __getattr__\n",
            "    module = self._get_module(self._class_to_module[name])\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1949, in _get_module\n",
            "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
            "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\", line 39, in <module>\n",
            "    from ...modeling_utils import ALL_ATTENTION_FUNCTIONS, PreTrainedModel\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 61, in <module>\n",
            "    from .loss.loss_utils import LOSS_MAPPING\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/loss/loss_utils.py\", line 19, in <module>\n",
            "    from .loss_deformable_detr import DeformableDetrForObjectDetectionLoss, DeformableDetrForSegmentationLoss\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/loss/loss_deformable_detr.py\", line 4, in <module>\n",
            "    from ..image_transforms import center_to_corners_format\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/image_transforms.py\", line 49, in <module>\n",
            "    import tensorflow as tf\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/__init__.py\", line 38, in <module>\n",
            "    from tensorflow.python.tools import module_util as _module_util\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/__init__.py\", line 37, in <module>\n",
            "    from tensorflow.python.eager import context\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\", line 34, in <module>\n",
            "    from tensorflow.python.client import pywrap_tf_session\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/client/pywrap_tf_session.py\", line 19, in <module>\n",
            "    from tensorflow.python.client._pywrap_tf_session import *\n",
            "\u001b[0m\u001b[0mAttributeError\u001b[0m: \u001b[0m_ARRAY_API not found\u001b[0m\n",
            "\u001b[0m\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.2.3 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"/content/low_bit_llama/llama_2b_inference.py\", line 62, in <module>\n",
            "    model, tokenizer = load_llama_model(model_uri, cache_dir=cache_dir, groupsize=args.groupsize, double_groupsize=double_groupsize, v1=v1, bits=2, half=True, asym=asym)\n",
            "  File \"/content/low_bit_llama/model.py\", line 136, in load_llama_model\n",
            "    from transformers import LlamaConfig, LlamaForCausalLM, LlamaTokenizer\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1938, in __getattr__\n",
            "    value = getattr(module, name)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1937, in __getattr__\n",
            "    module = self._get_module(self._class_to_module[name])\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1949, in _get_module\n",
            "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
            "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\", line 39, in <module>\n",
            "    from ...modeling_utils import ALL_ATTENTION_FUNCTIONS, PreTrainedModel\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 61, in <module>\n",
            "    from .loss.loss_utils import LOSS_MAPPING\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/loss/loss_utils.py\", line 19, in <module>\n",
            "    from .loss_deformable_detr import DeformableDetrForObjectDetectionLoss, DeformableDetrForSegmentationLoss\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/loss/loss_deformable_detr.py\", line 4, in <module>\n",
            "    from ..image_transforms import center_to_corners_format\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/image_transforms.py\", line 49, in <module>\n",
            "    import tensorflow as tf\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/__init__.py\", line 38, in <module>\n",
            "    from tensorflow.python.tools import module_util as _module_util\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/__init__.py\", line 37, in <module>\n",
            "    from tensorflow.python.eager import context\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\", line 36, in <module>\n",
            "    from tensorflow.python.eager import execute\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\", line 21, in <module>\n",
            "    from tensorflow.python.framework import dtypes\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/dtypes.py\", line 30, in <module>\n",
            "    from tensorflow.python.lib.core import _pywrap_float8\n",
            "\u001b[0m\u001b[0mAttributeError\u001b[0m: \u001b[0m_ARRAY_API not found\u001b[0m\n",
            "\u001b[0m\u001b[0mImportError\u001b[0m: \u001b[0mnumpy.core._multiarray_umath failed to import\u001b[0m\n",
            "\u001b[0m\u001b[0mImportError\u001b[0m: \u001b[0mnumpy.core.umath failed to import\u001b[0m\n",
            "\u001b[0m\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.2.3 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"/content/low_bit_llama/llama_2b_inference.py\", line 62, in <module>\n",
            "    model, tokenizer = load_llama_model(model_uri, cache_dir=cache_dir, groupsize=args.groupsize, double_groupsize=double_groupsize, v1=v1, bits=2, half=True, asym=asym)\n",
            "  File \"/content/low_bit_llama/model.py\", line 136, in load_llama_model\n",
            "    from transformers import LlamaConfig, LlamaForCausalLM, LlamaTokenizer\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1938, in __getattr__\n",
            "    value = getattr(module, name)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1937, in __getattr__\n",
            "    module = self._get_module(self._class_to_module[name])\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1949, in _get_module\n",
            "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
            "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\", line 39, in <module>\n",
            "    from ...modeling_utils import ALL_ATTENTION_FUNCTIONS, PreTrainedModel\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 61, in <module>\n",
            "    from .loss.loss_utils import LOSS_MAPPING\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/loss/loss_utils.py\", line 19, in <module>\n",
            "    from .loss_deformable_detr import DeformableDetrForObjectDetectionLoss, DeformableDetrForSegmentationLoss\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/loss/loss_deformable_detr.py\", line 4, in <module>\n",
            "    from ..image_transforms import center_to_corners_format\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/image_transforms.py\", line 49, in <module>\n",
            "    import tensorflow as tf\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/__init__.py\", line 38, in <module>\n",
            "    from tensorflow.python.tools import module_util as _module_util\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/__init__.py\", line 37, in <module>\n",
            "    from tensorflow.python.eager import context\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\", line 36, in <module>\n",
            "    from tensorflow.python.eager import execute\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\", line 21, in <module>\n",
            "    from tensorflow.python.framework import dtypes\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/dtypes.py\", line 30, in <module>\n",
            "    from tensorflow.python.lib.core import _pywrap_float8\n",
            "\u001b[0m\u001b[0mAttributeError\u001b[0m: \u001b[0m_ARRAY_API not found\u001b[0m\n",
            "\u001b[0m\u001b[0mImportError\u001b[0m: \u001b[0mnumpy.core._multiarray_umath failed to import\u001b[0m\n",
            "\u001b[0m\u001b[0mImportError\u001b[0m: \u001b[0mnumpy.core.umath failed to import\u001b[0m\n",
            "\u001b[0m\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.2.3 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"/content/low_bit_llama/llama_2b_inference.py\", line 62, in <module>\n",
            "    model, tokenizer = load_llama_model(model_uri, cache_dir=cache_dir, groupsize=args.groupsize, double_groupsize=double_groupsize, v1=v1, bits=2, half=True, asym=asym)\n",
            "  File \"/content/low_bit_llama/model.py\", line 136, in load_llama_model\n",
            "    from transformers import LlamaConfig, LlamaForCausalLM, LlamaTokenizer\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1938, in __getattr__\n",
            "    value = getattr(module, name)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1937, in __getattr__\n",
            "    module = self._get_module(self._class_to_module[name])\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1949, in _get_module\n",
            "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
            "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\", line 39, in <module>\n",
            "    from ...modeling_utils import ALL_ATTENTION_FUNCTIONS, PreTrainedModel\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 61, in <module>\n",
            "    from .loss.loss_utils import LOSS_MAPPING\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/loss/loss_utils.py\", line 19, in <module>\n",
            "    from .loss_deformable_detr import DeformableDetrForObjectDetectionLoss, DeformableDetrForSegmentationLoss\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/loss/loss_deformable_detr.py\", line 4, in <module>\n",
            "    from ..image_transforms import center_to_corners_format\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/image_transforms.py\", line 49, in <module>\n",
            "    import tensorflow as tf\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/__init__.py\", line 38, in <module>\n",
            "    from tensorflow.python.tools import module_util as _module_util\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/__init__.py\", line 37, in <module>\n",
            "    from tensorflow.python.eager import context\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\", line 36, in <module>\n",
            "    from tensorflow.python.eager import execute\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\", line 21, in <module>\n",
            "    from tensorflow.python.framework import dtypes\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/dtypes.py\", line 35, in <module>\n",
            "    from tensorflow.tsl.python.lib.core import pywrap_bfloat16\n",
            "\u001b[0m\u001b[0mAttributeError\u001b[0m: \u001b[0m_ARRAY_API not found\u001b[0m\n",
            "\u001b[0m\u001b[0mImportError\u001b[0m: \u001b[0mnumpy.core._multiarray_umath failed to import\u001b[0m\n",
            "\u001b[0m\u001b[0mImportError\u001b[0m: \u001b[0mnumpy.core.umath failed to import\u001b[0m\n",
            "\u001b[0m\u001b[0mTraceback (most recent call last):\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1949, in _get_module\n",
            "\u001b[0m\u001b[0m    \u001b[0mreturn importlib.import_module(\".\" + module_name, self.__name__)\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
            "\u001b[0m\u001b[0m    \u001b[0mreturn _bootstrap._gcd_import(name[level:], package, level)\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\n",
            "\u001b[0m\u001b[0m  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n",
            "\u001b[0m\u001b[0m  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\n",
            "\u001b[0m\u001b[0m  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\n",
            "\u001b[0m\u001b[0m  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
            "\u001b[0m\u001b[0m  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\", line 39, in <module>\n",
            "\u001b[0m\u001b[0m    \u001b[0mfrom ...modeling_utils import ALL_ATTENTION_FUNCTIONS, PreTrainedModel\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 61, in <module>\n",
            "\u001b[0m\u001b[0m    \u001b[0mfrom .loss.loss_utils import LOSS_MAPPING\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/transformers/loss/loss_utils.py\", line 19, in <module>\n",
            "\u001b[0m\u001b[0m    \u001b[0mfrom .loss_deformable_detr import DeformableDetrForObjectDetectionLoss, DeformableDetrForSegmentationLoss\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/transformers/loss/loss_deformable_detr.py\", line 4, in <module>\n",
            "\u001b[0m\u001b[0m    \u001b[0mfrom ..image_transforms import center_to_corners_format\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/transformers/image_transforms.py\", line 49, in <module>\n",
            "\u001b[0m\u001b[0m    \u001b[0mimport tensorflow as tf\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/__init__.py\", line 38, in <module>\n",
            "\u001b[0m\u001b[0m    \u001b[0mfrom tensorflow.python.tools import module_util as _module_util\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/__init__.py\", line 37, in <module>\n",
            "\u001b[0m\u001b[0m    \u001b[0mfrom tensorflow.python.eager import context\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\", line 36, in <module>\n",
            "\u001b[0m\u001b[0m    \u001b[0mfrom tensorflow.python.eager import execute\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\", line 21, in <module>\n",
            "\u001b[0m\u001b[0m    \u001b[0mfrom tensorflow.python.framework import dtypes\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/dtypes.py\", line 38, in <module>\n",
            "\u001b[0m\u001b[0m    \u001b[0m_np_bfloat16 = pywrap_bfloat16.bfloat16_type()\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0mTypeError\u001b[0m: \u001b[0mUnable to convert function return value to a Python type! The signature was\n",
            "\t() -> handle\u001b[0m\n",
            "\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0mThe above exception was the direct cause of the following exception:\n",
            "\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0mTraceback (most recent call last):\n",
            "\u001b[0m\u001b[0m  File \"/content/low_bit_llama/llama_2b_inference.py\", line 62, in <module>\n",
            "\u001b[0m\u001b[0m    \u001b[0mmodel, tokenizer = load_llama_model(model_uri, cache_dir=cache_dir, groupsize=args.groupsize, double_groupsize=double_groupsize, v1=v1, bits=2, half=True, asym=asym)\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/content/low_bit_llama/model.py\", line 136, in load_llama_model\n",
            "\u001b[0m\u001b[0m    \u001b[0mfrom transformers import LlamaConfig, LlamaForCausalLM, LlamaTokenizer\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"<frozen importlib._bootstrap>\", line 1229, in _handle_fromlist\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1938, in __getattr__\n",
            "\u001b[0m\u001b[0m    \u001b[0mvalue = getattr(module, name)\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1937, in __getattr__\n",
            "\u001b[0m\u001b[0m    \u001b[0mmodule = self._get_module(self._class_to_module[name])\u001b[0m\n",
            "\u001b[0m\u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m \u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m^\u001b[0m\n",
            "\u001b[0m\u001b[0m  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1951, in _get_module\n",
            "\u001b[0m\u001b[0m    \u001b[0mraise RuntimeError(\u001b[0m\n",
            "\u001b[0m\u001b[0mRuntimeError\u001b[0m: \u001b[0mFailed to import transformers.models.llama.modeling_llama because of the following error (look up to see its traceback):\n",
            "Unable to convert function return value to a Python type! The signature was\n",
            "\t() -> handle\u001b[0m\n",
            "\u001b[0m\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uvrJ70R61LLy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}